<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Deep Learning</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css" integrity="sha512-...">
    <link rel="stylesheet" href="style1.css">
    <script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>
</head>
<body>

    <nav>
        <div class="navigation">
                <div class="logo">
                  <img src="https://img.freepik.com/free-vector/teamwork-concept-with-people-desk_23-2147771571.jpg?t=st=1713430833~exp=1713434433~hmac=953a14ea602a2727c6cbf2ac76332f6b9eb33d6bc1fef013aa1403705363189f&w=740">
                  <h1>VSS</h1>
                </div>
                <ul>
                    <li class="list active">
                        <a href="index.html">
                            <span class="icon">
                                <ion-icon name="home-outline"></ion-icon>
                            </span>
                            <span class="text">Home</span>
                        </a>
                     </li>
                     <li class="list active">
                        <a href="#">
                            <span class="icon">
                                <ion-icon name="chatbubbles-outline"></ion-icon>
                            </span>
                            <span class="text">Chat</span>
                        </a>
                     </li>
                     <li class="list active">
                        <a href="index.html#" onclick="scrollToMeetContainer()">
                            <span class="icon"><ion-icon name="camera-reverse-outline"></ion-icon>
                            </span>
                            <span class="text">Meet</span>
                        </a>
                     </li>
                     <li class="list active">
                        <a href="#">
                            <span class="icon"><ion-icon name="search-outline"></ion-icon></span>
                            <span class="text">Search</span>
                        </a>
                     </li>
                     <li class="list active">
                        <a href="#">
                            <span class="icon"><ion-icon name="settings-outline"></ion-icon>
                            </span>
                            <span class="text">Setting</span>
                        </a>
                     </li>
                </ul>
                <button>login</button>
        </div>
      </nav>


        <div class="start">
            
            <div class="sidenav">
                <h3>Menu</h3>
                <ul>
                    <li>
                        <a href="deeplearn.html#section0">Introduction</a>
                    </li>
                    <li>
                        <a href="deeplearn.html#section1">Difference between Machine Learning and Deep Learning</a>
                    </li>
                    <li>
                        <a href="deeplearn.html#section2">Applications of Deep Learning</a>
                    </li>
                    <li>
                        <a href="deeplearn.html#section3">Challenges in Deep Learning</a>
                    </li>
                    <li>
                        <a href="deeplearn.html#section4">Pros and cons of Deep Learning</a>
                    </li>
                    <li>
                        <a href="deeplearn.html#section5">Neural Network</a>
                    </li>
                    <li>
                        <details id="deeplearn.html#section6">
                            <summary>Artificial Neural Network</summary>
                            <li>
                                <a href="deeplearn.html#section6.1">Introduction</a>
                            </li>
                            <li>
                                <a href="deeplearn.html#section6.2">Relationship between BNN and ANN</a>
                            </li>
                            <li>
                                <a href="deeplearn.html#section6.3">Architecture</a>
                            </li>
                            <li>
                                <a href="deeplearn.html#section6.4">Pros and Cons</a>
                            </li>
                            <li>
                                <a href="deeplearn.html#section6.5">Working</a>
                            </li>
                            <li>
                                <a href="deeplearn.html#section6.6">Types of ANN</a>
                            </li>
                        </details>
                    </li>
                    <li>
                        <details id="deeplearn.html#section7">
                            <summary>Convolutional Neural Network</summary>
                            <li>
                                <a href="deeplearn.html#section7.1">Introduction</a>
                            </li>
                            <li>
                                <a href="deeplearn.html#section7.2">Working</a>
                            </li>
                            <li>
                                <a href="deeplearn.html#section7.3">Types of CNN</a>
                            </li>
                            <li>
                                <a href="deeplearn.html#section7.4">Advantages</a>
                            </li>
                            <li>
                                <a href="deeplearn.html#section7.5">Disadvantages</a>
                            </li>
                            <li>
                                <a href="deeplearn.html#section7.6">Applications</a>
                            </li>
                            <li>
                                <a href="deeplearn.html#section7.7">Tools and Frameworks</a>
                            </li>
                        </details>
                    </li>
                    <li>
                        <details id="deeplearn.html#section8">
                            <summary>Recurrent Neural Network</summary>
                            <li>
                                <a href="deeplearn.html#section8.1">Introduction</a>
                            </li>
                            <li>
                                <a href="deeplearn.html#section8.2">Architecture</a>
                            </li>
                            <li>
                                <a href="deeplearn.html#section8.3">Working</a>
                            </li>
                            <li>
                                <a href="deeplearn.html#section8.4">Backpropagation Through Time</a>
                            </li>
                            <li>
                                <a href="deeplearn.html#section8.5">Types of RNN</a>
                            </li>
                            <li>
                                <a href="deeplearn.html#section8.6">Comparison</a>
                            </li>
                            <li>
                                <a href="deeplearn.html#section8.7">Pros and cons</a>
                            </li>
                            <li>
                                <a href="deeplearn.html#section8.8">Applications</a>
                            </li>
                        </details>
                    </li>
                    <li>
                        <details id="next.html#section9">
                            <summary>Region-based Convolutional Neural Network(R-CNN)</summary>
                            <li>
                                <a href="next.html#section9.1">Introduction</a>
                            </li>
                            <li>
                                <a href="next.html#section9.2">Working</a>
                            </li>
                            <li>
                                <a href="next.html#section9.3">
                                    Architecture
                                </a>
                            </li>
                            <li>
                                <a href="next.html#section9.4">SVM</a>
                            </li>
                            <li>
                                <a href="next.html#section9.5">Challenges</a>
                            </li>
                        </details>
                    </li>                       
                    <li>
                        <details id="next.html#section11">
                            <summary>Long Short-term Memory Networks</summary>
                            <li>
                                <a href="next.html#section11.0">Introduction</a>
                            </li>
                            <li>
                                <a href="next.html#section11.1">Architecture</a>
                            </li>
                            <li>
                                <a href="next.html#section11.2">Working</a>
                            </li>
                        </details>
                    </li>
                    <li>
                        <details id="next.html#section12">
                            <summary>Activation Functions</summary>
                            <li>
                                <a href="next.html#section12.1">Elements</a>
                            </li>
                            <li>
                                <a href="next.html#section12.2">Use</a>
                            </li>
                            <li>
                                <a href="next.html#section12.3">Non-linear activation function</a>
                            </li>
                            <li>
                                <a href="next.html#section12.4">Variants</a>
                            </li>
                        </details>
                    </li>                      
                    <li>
                        <details id="next.html#section14">
                            <summary>Optimizers</summary>
                            <li>
                                <a href="next.html#section14.1">Introduction</a>
                            </li>
                            <li>
                                <a href="next.html#section14.2">Types</a>
                            </li>
                        </details>
                    </li>                    
                    <li>
                        <details id="next.html#section16">
                            <summary>Autoencoders</summary>
                            <li>
                                <a href="next.html#section16.1">Introduction</a>
                            </li>
                            <li>
                                <a href="next.html#section16.2">Architecture</a>
                            </li>
                            <li>
                                <a href="next.html#section16.3">Types</a>
                            </li>
                        </details>
                    </li>
                    <li>
                        <a href="next.html#section10">Generative Adversarial Networks(GANs)</a>
                    </li>
                    <li>
                        <a href="next.html#section13">Difference between ANN and BNN</a>
                    </li>
                    <li>
                        <a href="next.html#section15">Loss Function</a>
                    </li>
                </ul>
            </div>

            <div class="main">

            <div class="intro" id="section0">
            <h1>Introduction to Deep Learning<hr size=".1px" color="gray"></h1>
            <p>
                Deep learning is a branch of machine learning which is based on artificial neural networks. It is capable of learning complex patterns and relationships within data. In deep learning, we don’t need to explicitly program everything. It has become increasingly popular in recent years due to the advances in processing power and the availability of large datasets. Because it is based on artificial neural networks (ANNs) also known as deep neural networks (DNNs). These neural networks are inspired by the structure and function of the human brain’s biological neurons, and they are designed to learn from large amounts of data.
            </p>
            <p>
                Deep Learning is a subfield of Machine Learning that involves the use of neural networks to model and solve complex problems. Neural networks are modeled after the structure and function of the human brain and consist of layers of interconnected nodes that process and transform data.
                The key characteristic of Deep Learning is the use of deep neural networks, which have multiple layers of interconnected nodes. These networks can learn complex representations of data by discovering hierarchical patterns and features in the data. Deep Learning algorithms can automatically learn and improve from data without the need for manual feature engineering.
                Deep Learning has achieved significant success in various fields, including image recognition, natural language processing, speech recognition, and recommendation systems. Some of the popular Deep Learning architectures include Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), and Deep Belief Networks (DBNs).
                Training deep neural networks typically requires a large amount of data and computational resources. However, the availability of cloud computing and the development of specialized hardware, such as Graphics Processing Units (GPUs), has made it easier to train deep neural networks.
            </p>

            <div class="fig1">
                <img src="https://www.researchgate.net/publication/373797588/figure/fig1/AS:11431281187528395@1694271303862/A-comparative-view-of-AI-machine-learning-deep-learning-and-generative-AI-source.png" alt="Deep_Learning">
                <div class="caption"><i>Fig - introduction to Deep Learning</i></div>
            </div>

            </div>

            <div class="intro">
            <h1>What is Deep Learning?<hr size=".1px" color="gray"></h1>
            <p>
                Deep learning is a branch of machine learning which is based on artificial neural networks. It is capable of learning complex patterns and relationships within data. In deep learning, we don’t need to explicitly program everything. It has become increasingly popular in recent years due to the advances in processing power and the availability of large datasets. Because it is based on artificial neural networks (ANNs) also known as deep neural networks (DNNs). These neural networks are inspired by the structure and function of the human brain’s biological neurons, and they are designed to learn from large amounts of data.
            </p>
            <p>
                An artificial neural network or ANN uses layers of interconnected nodes called neurons that work together to process and learn from the input data.
                <br>
                In a fully connected Deep neural network, there is an input layer and one or more hidden layers connected one after the other. Each neuron receives input from the previous layer neurons or the input layer. The output of one neuron becomes the input to other neurons in the next layer of the network, and this process continues until the final layer produces the output of the network. The layers of the neural network transform the input data through a series of nonlinear transformations, allowing the network to learn complex representations of the input data.
                <br><br>
                Deep learning can be used for supervised, unsupervised as well as reinforcement machine learning. it uses a variety of ways to process these.
                
                <ol>
                    <li>
                        Machine Learning : Supervised machine learning is the machine learning technique in which the neural network learns to make predictions or classify data based on the labeled datasets. Here we input both input features along with the target variables. the neural network learns to make predictions based on the cost or error that comes from the difference between the predicted and the actual target, this process is known as backpropagation.  Deep learning algorithms like Convolutional neural networks, Recurrent neural networks are used for many supervised tasks like image classifications and recognization, sentiment analysis, language translations, etc.
                    </li>
                    <br>
                    <li>
                        Unsupervised Machine Learning : Unsupervised machine learning is the machine learning technique in which the neural network learns to discover the patterns or to cluster the dataset based on unlabeled datasets. Here there are no target variables. while the machine has to self-determined the hidden patterns or relationships within the datasets. Deep learning algorithms like autoencoders and generative models are used for unsupervised tasks like clustering, dimensionality reduction, and anomaly detection.
                    </li>
                    <br>
                    <li>
                        Reinforcement  Machine Learning : Reinforcement  Machine Learning is the machine learning technique in which an agent learns to make decisions in an environment to maximize a reward signal. The agent interacts with the environment by taking action and observing the resulting rewards. Deep learning can be used to learn policies, or a set of actions, that maximizes the cumulative reward over time. Deep reinforcement learning algorithms like Deep Q networks and Deep Deterministic Policy Gradient (DDPG) are used to reinforce tasks like robotics and game playing etc.
                    </li>
                </ol>
            </p>
            </div>

            <div class="headline">
            Table of Content<hr size=".1px" color="gray">
            </div>

            <div class="index glass" id="index">
            <ul>
                <li>
                    <a href="#section1">Difference between Machine Learning and Deep Learning</a>
                </li>
                <li>
                    <a href="#section2">Applications of Deep Learning</a>
                </li>
                <li>
                    <a href="#section3">Challenges in Deep Learning</a>
                </li>
                <li>
                    <a href="#section4">Pros and Cons of Deep Learning</a>
                </li>
            </ul>
            <ul>
                <li>
                    <a href="#section5">Neural Network</a>
                </li> 
                <li>
                    <a href="#section6">Artificial Neural Networks(ANN)</a>
                </li>
                <li>
                    <a href="#section7">Convolutional Neural Network(CNN)</a>
                </li>
                <li>
                    <a href="#section8">Recurrent Neural Network(RNN)</a>
                </li>
            </ul>
            <br>

            </div>

            <div class="containr">

                <div class="section one" id="section1">
                <div class="headline">1. Difference between Machine Learning and Deep Learning<hr size=".1px" color="gray"></div>
                <div class="difference" id="section1.1">
                    <table>
                <tr>
                    <th>Machine Learning</th>
                    <th>Deep Learning</th>
                </tr>
                <tr>
                    <td>i. Apply statistical algorithms to learn the hidden patterns and relationships in the dataset.
                    </td>
                    <td>i. Uses artificial neural network architecture to learn the hidden patterns and relationships in the dataset</td>
                </tr>
                <tr>
                    <td>
                        ii. Can work on the smaller amount of dataset
                    </td>
                    <td>
                        ii. Requires the larger volume of dataset compared to machine learning
                    </td>
                </tr>
                <tr>
                    <td>
                        iii. Better for the low-label task.
                    </td>
                    <td>
                        iii. Better for complex task like image processing, natural language processing, etc.
                    </td>
                </tr>
                <tr>
                    <td>
                        iv. Takes less time to train the model.
                    </td>
                    <td>
                        iv. Takes more time to train the model.
                    </td>
                </tr>
                <tr>
                    <td>
                        v. A model is created by relevant features which are manually extracted from images to detect an object in the image.
                    </td>
                    <td>
                        v. Relevant features are automatically extracted from images. It is an end-to-end learning process
                    </td>
                </tr>
                <tr>
                    <td>
                        vi. Less complex and easy to interpret the result.
                    </td>
                    <td>
                        vi. More complex, it works like the black box interpretations of the result are not easy.
                    </td>
                </tr>
                <tr>
                    <td>
                        vii. It can work on the CPU or requires less computing power as compared to deep learning.
                    </td>
                    <td>
                        vii. It requires a high-performance computer with GPU.
                    </td>
                </tr>
                    </table>
                </div> 
                </div>
        
                <div class="indx" id="scrollToTop">
                <a href="#index"><i class="fas fa-arrow-circle-up"></i></a>
                </div>

                <div class="section two" id="section2">
                    <div class="headline">2. Applications of Deep Learning<hr size=".1px" color="gray"></div>
                    <p>The main applications of deep learning can be divided into computer vision, natural language processing (NLP), and reinforcement learning. </p>
                    <ol type="i">
                        <li>Computer vision : In computer vision, Deep learning models can enable machines to identify and understand visual data.  Some of the main applications of deep learning in computer vision include:
                        </li>
                        <ol type="a">
                            <li>
                                Object detection and recognition: Deep learning model can be used to identify and locate objects within images and videos, making it possible for machines to perform tasks such as self-driving cars, surveillance, and robotics. 
                            </li>
                            <li>
                                Image classification: Deep learning models can be used to classify images into categories such as animals, plants, and buildings. This is used in applications such as medical imaging, quality control, and image retrieval. 
                            </li>
                            <li>
                                Image segmentation: Deep learning models can be used for image segmentation into different regions, making it possible to identify specific features within images.
                            </li>
                        </ol>

                        <br>

                        <li>Natural language processing (NLP) : In NLP, the  Deep learning model can enable machines to understand and generate human language. Some of the main applications of deep learning in NLP include: </li>
            
                        <ol type="a">
                            <li>
                                Automatic Text Generation - Deep learning model can learn the corpus of text and new text like summaries, essays can be automatically generated using these trained models.
                            </li>
                            <li>
                                Language translation: Deep learning models can translate text from one language to another, making it possible to communicate with people from different linguistic backgrounds.
                            </li>
                            <li>
                                Sentiment analysis: Deep learning models can analyze the sentiment of a piece of text, making it possible to determine whether the text is positive, negative, or neutral. This is used in applications such as customer service, social media monitoring, and political analysis. 
                            </li>
                            <li>
                                Speech recognition: Deep learning models can recognize and transcribe spoken words, making it possible to perform tasks such as speech-to-text conversion, voice search, and voice-controlled devices.
                            </li>
                        </ol>

                        <br>
            
                        <li>Reinforcement learning: In reinforcement learning, deep learning works as training agents to take action in an environment to maximize a reward. Some of the main applications of deep learning in reinforcement learning include: 
                        </li>
                        <ol type="a">
                            <li>
                                Game playing: Deep reinforcement learning models have been able to beat human experts at games such as Go, Chess, and Atari. 
                            </li>
                            <li>
                                Robotics: Deep reinforcement learning models can be used to train robots to perform complex tasks such as grasping objects, navigation, and manipulation. 
                            </li>
                            <li>
                                Control systems: Deep reinforcement learning models can be used to control complex systems such as power grids, traffic management, and supply chain optimization. 
                            </li>
                        </ol>
                    </ol>
                </div>

                <div class="section three" id="section3">
                    <div class="headline">3. Challenges in Deep Learning<hr size=".1px" color="gray"></div>
                    <p>Deep learning has made significant advancements in various fields, but there are still some challenges that need to be addressed. Here are some of the main challenges in deep learning:</p>
                    <ol type="i">
                        <li>
                            Data availability: It requires large amounts of data to learn from. For using deep learning it’s a big concern to gather as much data for training.
                        </li>
                        <li>
                            Computational Resources: For training the deep learning model, it is computationally expensive because it requires specialized hardware like GPUs and TPUs.
                        </li>
                        <li>
                            Time-consuming: While working on sequential data depending on the computational resource it can take very large even in days or months. 
                        </li>
                        <li>
                            Interpretability: Deep learning models are complex, it works like a black box. it is very difficult to interpret the result.
                        </li>
                        <li>
                            Overfitting: when the model is trained again and again, it becomes too specialized for the training data, leading to overfitting and poor performance on new data.
                        </li>
                    </ol>
                </div>

                <div class="section four" id="section4">
                    <div class="headline">4. Pros and Cons of Deep Learning<hr size=".1px" color="gray"></div>
                    <p><b>Advantages :</b></p>
                    <ol type="i">
                        <li>
                            High accuracy: Deep Learning algorithms can achieve state-of-the-art performance in various tasks, such as image recognition and natural language processing.
                        </li>

                        <li>
                            Automated feature engineering: Deep Learning algorithms can automatically discover and learn relevant features from data without the need for manual feature engineering.
                        </li>

                        <li>
                            Scalability: Deep Learning models can scale to handle large and complex datasets, and can learn from massive amounts of data.
                        </li>

                        <li>
                            Flexibility: Deep Learning models can be applied to a wide range of tasks and can handle various types of data, such as images, text, and speech.
                        </li>

                        <li>
                            Continual improvement: Deep Learning models can continually improve their performance as more data becomes available.
                        </li>
                    </ol>

                    <p><b>Disadvantages :</b></p>
                    <ol type="i">
                        <li>
                            High computational requirements: Deep Learning models require large amounts of data and computational resources to train and optimize.
                        </li>
                        <li>
                            Requires large amounts of labeled data: Deep Learning models often require a large amount of labeled data for training, which can be expensive and time- consuming to acquire.
                        </li>

                        <li>
                            Interpretability: Deep Learning models can be challenging to interpret, making it difficult to understand how they make decisions.
                        </li>

                        <li>
                            Overfitting: Deep Learning models can sometimes overfit to the training data, resulting in poor performance on new and unseen data.
                        </li>

                        <li>
                            Black-box nature: Deep Learning models are often treated as black boxes, making it difficult to understand how they work and how they arrived at their predictions.
                        </li>
                    </ol>
                    <p>
                        <i> In summary, while Deep Learning offers many advantages, including high accuracy and scalability, it also has some disadvantages, such as high computational requirements, the need for large amounts of labeled data, and interpretability challenges. These limitations need to be carefully considered when deciding whether to use Deep Learning for a specific task.</i>
                    </p>
                </div>

                <div class="section five" id="section5">
                    <div class="headline">5. Neural Network<hr size=".1px" color="gray"></div>
                    <p>
                        Neural Networks are computational models that mimic the complex functions of the human brain. The neural networks consist of interconnected nodes or neurons that process and learn from data, enabling tasks such as pattern recognition and decision making in machine learning, Or we can say that neural network is a method in artificial intelligence that teaches computers to process data in a way that is inspired by the human brain.
                
                        <br><br> It is a type of machine learning process, called deep learning, that uses interconnected nodes or neurons in a layered structure that resembles the human brain. It creates an adaptive system that computers use to learn from their mistakes and improve continuously. Thus, artificial neural networks attempt to solve complicated problems, like summarizing documents or recognizing faces, with greater accuracy.
                <br><br>
                Neural networks can help computers make intelligent decisions with limited human assistance. This is because they can learn and model the relationships between input and output data that are nonlinear and complex.
                <br><br>
                For detailed information,check out the video provided below.
                <br>
                <iframe 
                src="https://www.youtube.com/embed/aircAruvnKk" id="frame">
                </iframe>
                    </p>
                </div>

                <div class="section six" id="section6">
                    <div class="headline">
                        6. Artificial Neural Networks(ANN)<hr size=".1px" color="gray">
                    </div>
                    <div class="introduction" id="section6.1">
                        <h3>6.1. Introduction</h3>
                        <p>
                            The term "Artificial Neural Network" is derived from Biological neural networks that develop the structure of a human brain. Similar to the human brain that has neurons interconnected to one another, artificial neural networks also have neurons that are interconnected to one another in various layers of the networks. These neurons are known as nodes or units. These units are arranged in a series of layers that together constitute the whole Artificial Neural Network in a system.
                        </p>
                        <br>
                        <p>
                            The structures and operations of human neurons serve as the basis for artificial neural networks. It is also known as neural networks or neural nets. The input layer of an artificial neural network is the first layer, and it receives input from external sources and releases it to the hidden layer, which is the second layer. In the hidden layer, each neuron receives input from the previous layer neurons, computes the weighted sum, and sends it to the neurons in the next layer. These connections are weighted means effects of the inputs from the previous layer are optimized more or less by assigning different-different weights to each input and it is adjusted during the training process by optimizing these weights for improved model performance. 
                        </p>
                    
                        <div class="fig2">
                            <img src="https://static.javatpoint.com/tutorial/artificial-neural-network/images/artificial-neural-network2.png" alt="ANN">
                            <div class="caption">Fig 6.1.1</div>
                        </div>
                
                        <div class="fig2">
                            <img src="https://static.javatpoint.com/tutorial/artificial-neural-network/images/artificial-neural-network3.png" alt="ANN">
                            <div class="caption">Fig 6.1.2</div>
                        </div>

                        <p>
                            Dendrites from Biological Neural Network represent inputs in Artificial Neural Networks, cell nucleus represents Nodes, synapse represents Weights, and Axon represents Output.
                            <br><br>
                            The concept of artificial neural networks comes from biological neurons found in animal brains So they share a lot of similarities in structure and function wise.
                        </p>

                        <br><br>
                        <p>
                            <b>i. Structure :</b> The structure of artificial neural networks is inspired by biological neurons. A biological neuron has a cell body or soma to process the impulses, dendrites to receive them, and an axon that transfers them to other neurons.  The input nodes of artificial neural networks receive input signals, the hidden layer nodes compute these input signals, and the output layer nodes compute the final output by processing the hidden layer’s results using activation functions.
                        </p>

                        <br>
                        <p>
                            <b>ii.. Synapses :</b> Synapses are the links between biological neurons that enable the transmission of impulses from dendrites to the cell body. Synapses are the weights that join the one-layer nodes to the next-layer nodes in artificial neurons. The strength of the links is determined by the weight value. 
                        </p>

                        <br>
                        <p>
                            <b>iii. Learning :</b> In biological neurons, learning happens in the cell body nucleus or soma, which has a nucleus that helps to process the impulses. An action potential is produced and travels through the axons if the impulses are powerful enough to reach the threshold. This becomes possible by synaptic plasticity, which represents the ability of synapses to become stronger or weaker over time in reaction to changes in their activity. In artificial neural networks, backpropagation is a technique used for learning, which adjusts the weights between nodes according to the error or differences between predicted and actual outcomes.
                        </p>
                        <br>
                        <p>
                             <b>iv. Activation :</b> In biological neurons, activation is the firing rate of the neuron which happens when the impulses are strong enough to reach the threshold. In artificial neural networks, A mathematical function known as an activation function maps the input to the output, and executes activations.
                        </p>
                        
                    </div>

                    <br>

                    <div class="relation" id="section6.2">
                <h3>6.2. Relationship between Biological neural network and artificial neural network</h3>
                <br>
                <div class="table2">
                    <table>
                    <tr>
                        <th>Biological Neural Network</th>
                        <th>Artificial Neural Network</th>
                    </tr>
                    <tr>
                        <td>Dendrites
                        </td>
                        <td>Inputs
                        </td>
                    </tr>
                    <tr>
                        <td>
                            Cell nucleus
                        </td>
                        <td>
                            Nodes
                        </td>
                    </tr>
                    <tr>
                        <td>
                            Synapse
                        </td>
                        <td>
                            Weights
                        </td>
                    </tr>
                    <tr>
                        <td>
                            Axon
                        </td>
                        <td>
                            Output
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <em>Biological Neuron :</em> Synaptic plasticity	
                        </td>
                        <td>                           
                            <em>Artificial Neuron :</em> Backpropagations
                        </td>
                    </tr>
                    </table>
                </div>

                <br>

                <p> 
                    A layer can have only a dozen units or millions of units as this depends on how the complex neural networks will be required to learn the hidden patterns in the dataset. Commonly, Artificial Neural Network has an input layer, an output layer as well as hidden layers. The input layer receives data from the outside world which the neural network needs to analyze or learn about. Then this data passes through one or multiple hidden layers that transform the input into data that is valuable for the output layer. Finally, the output layer provides an output in the form of a response of the Artificial Neural Networks to input data provided. In the majority of neural networks, units are interconnected from one layer to another. Each of these connections has weights that determine the influence of one unit on another unit. As the data transfers from one unit to another, the neural network learns more and more about the data which eventually results in an output from the output layer.
                </p>

                <br>
                    </div>

                <div class="Architecture" id="section6.3">
                <h3>6.3. Architecture of Artificial Neural Network (ANN) :</h3>
                <p>
                    To understand the concept of the architecture of an artificial neural network, we have to understand what a neural network consists of. In order to define a neural network that consists of a large number of artificial neurons, which are termed units arranged in a sequence of layers. Lets us look at various types of layers available in an artificial neural network.
                </p>
                <br>
                <p>
                    Artificial Neural Network primarily consists of three layers :
                </p>
                <br>
                <p>
                    <p><b>i. Input Layer :</b>
                        As the name suggests, it accepts inputs in several different formats provided by the programmer.
                    </p>
                    <br>
                    <p><b>ii. Hidden Layer :</b>
                        The hidden layer presents in-between input and output layers. It performs all the calculations to find hidden features and patterns.
                    </p>
                    <br>
                    <p><b>iii. Output Layer :</b>
                        The input goes through a series of transformations using the hidden layer, which finally results in output that is conveyed using this layer.
                    </p>
                </p>

                <div class="fig1">
                    <img src="https://media.geeksforgeeks.org/wp-content/cdn-uploads/20230602113310/Neural-Networks-Architecture.png" alt="ANN">
                    <div class="caption">Fig 6.3</div>
                </div>
                </div>   

                <div class="Proscons" id="section6.4">
                <h3>6.4. Pros and Cons of ANN</h3>
                <p>
                    An Artificial Neural Network in the field of Artificial intelligence where it attempts to mimic the network of neurons makes up a human brain so that computers will have an option to understand things and make decisions in a human-like manner. The artificial neural network is designed by programming computers to behave simply like interconnected brain cells.
                </p>
                <br>
                <h4>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;6.4.1. Advantages of Artificial Neural Network :</h4>
                <ol type="i">
                    <li>
                        <b>Parallel processing capability : </b>Artificial neural networks have a numerical value that can perform more than one task simultaneously.
                    </li>
                    <li>
                        <b>Storing data on the entire network :</b> Data that is used in traditional programming is stored on the whole network, not on a database. The disappearance of a couple of pieces of data in one place doesn't prevent the network from working.
                    </li>
                    <li>
                        <b>Capability to work with incomplete knowledge :</b> After ANN training, the information may produce output even with inadequate data. The loss of performance here relies upon the significance of missing data.
                    </li>
                    <li>
                        <b>Having a memory distribution :</b> For ANN is to be able to adapt, it is important to determine the examples and to encourage the network according to the desired output by demonstrating these examples to the network. The succession of the network is directly proportional to the chosen instances, and if the event can't appear to the network in all its aspects, it can produce false output.
                    </li>
                    <li>
                        <b>Having fault tolerance :</b> Extortion of one or more cells of ANN does not prohibit it from generating output, and this feature makes the network fault-tolerance.
                    </li>
                </ol>
                <br>
                <h4>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;6.4.2. Disadvantages of Artificial Neural Network :</h4>
                <ol type="i">
                    <li>
                        <b>Assurance of proper network structure :</b> There is no particular guideline for determining the structure of artificial neural networks. The appropriate network structure is accomplished through experience, trial, and error.
                    </li>
                    <li>
                        <b>Unrecognized behavior of the network :</b> It is the most significant issue of ANN. When ANN produces a testing solution, it does not provide insight concerning why and how. It decreases trust in the network.
                    </li>
                    <li>
                        <b>Hardware dependence :</b> Artificial neural networks need processors with parallel processing power, as per their structure. Therefore, the realization of the equipment is dependent.
                    </li>
                    <li>
                        <b>Difficulty of showing the issue to the network :</b> ANNs can work with numerical data. Problems must be converted into numerical values before being introduced to ANN. The presentation mechanism to be resolved here will directly impact the performance of the network. It relies on the user's abilities.
                    </li>
                    <li>
                        <b>The duration of the network is unknown :</b> The network is reduced to a specific value of the error, and this value does not give us optimum results.
                    </li>
                </ol>
                </div>

                <br>

                <div class="working" id="section6.5">
                <h3>6.5. How do artificial neural networks work?</h3>
                <p>
                    Artificial Neural Network can be best represented as a weighted directed graph, where the artificial neurons form the nodes. The association between the neurons outputs and neuron inputs can be viewed as the directed edges with weights. The Artificial Neural Network receives the input signal from the external source in the form of a pattern and image in the form of a vector. These inputs are then mathematically assigned by the notations x(n) for every n number of inputs.
                </p>
                <div class="fig2">
                    <img src="https://static.javatpoint.com/tutorial/artificial-neural-network/images/artificial-neural-network6.png" alt="ANN">
                    <div class="caption">Fig 6.5</div>
                </div>
                <p>
                    Afterward, each of the input is multiplied by its corresponding weights ( these weights are the details utilized by the artificial neural networks to solve a specific problem ). In general terms, these weights normally represent the strength of the interconnection between neurons inside the artificial neural network. All the weighted inputs are summarized inside the computing unit.
                </p>
                <p>
                    If the weighted sum is equal to zero, then bias is added to make the output non-zero or something else to scale up to the system's response. Bias has the same input, and weight equals to 1. Here the total of weighted inputs can be in the range of 0 to positive infinity. Here, to keep the response in the limits of the desired value, a certain maximum value is benchmarked, and the total of weighted inputs is passed through the activation function.
                </p>
                <p>
                    The activation function refers to the set of transfer functions used to achieve the desired output. There is a different kind of the activation function, but primarily either linear or non-linear sets of functions. Some of the commonly used sets of activation functions are the Binary, linear, and Tan hyperbolic sigmoidal activation functions. Let us take a look at each of them in details:
                </p>
                <p>
                    1. <b>Binary :</b> In binary activation function, the output is either a one or a 0. Here, to accomplish this, there is a threshold value set up. If the net weighted input of neurons is more than 1, then the final output of the activation function is returned as one or else the output is returned as 0.
                </p>
                <p>
                    2. <b>Sigmoidal Hyperbolic :</b> The Sigmoidal Hyperbola function is generally seen as an <b>"S"</b> shaped curve. Here the tan hyperbolic function is used to approximate output from the actual net input. The function is defined as:
                    <br><br>
                    <b>F(x) = (1/1 + exp(-????x))</b>
                    <br><br>
                    Where ???? is considered the Steepness parameter.
                </p>
                </div>
            
                <br>

                <div class="types" id="section6.6">
                <h3>6.6. Types of Artificial Neural Network :</h3>
                <p>
                    There are various types of Artificial Neural Networks (ANN) depending upon the human brain neuron and network functions, an artificial neural network similarly performs tasks. The majority of the artificial neural networks will have some similarities with a more complex biological partner and are very effective at their expected tasks. For example, segmentation or classification
                </p>
                <ol type="i">
                    <li>
                        <b>Feedback ANN :</b> In this type of ANN, the output returns into the network to accomplish the best-evolved results internally. As per the <b>University of Massachusetts</b>, Lowell Centre for Atmospheric Research. The feedback networks feed information back into itself and are well suited to solve optimization issues. The Internal system error corrections utilize feedback ANNs.
                    </li>
                    <li>
                        <b>Feed-Forward ANN :</b> A feed-forward network is a basic neural network comprising of an input layer, an output layer, and at least one layer of a neuron. Through assessment of its output by reviewing its input, the intensity of the network can be noticed based on group behavior of the associated neurons, and the output is decided. The primary advantage of this network is that it figures out how to evaluate and recognize input patterns.
                    </li>
                </ol>
                </div>
                </div>

                <div class="section seven" id="section7">
            <div class="headline">7.Convolutional Neural Network(CNN)<hr size=".1px" color="gray"></div>
            <div class="introduction" id="section7.1">
                <h3>7.1.  Introduction to CNN</h3>
                <p>
                    A Convolutional Neural Network (CNN) is a type of Deep Learning neural network architecture commonly used in Computer Vision. Computer vision is a field of Artificial Intelligence that enables a computer to understand and interpret the image or visual data.
                    <br>
                    <div class="fig1">
                    <img src="https://media.geeksforgeeks.org/wp-content/uploads/20231218174301/max.png" alt="ANN">
                    <div class="caption">Fig 7.1</div>
                    </div>
                </p>
            </div>
    
            <div class="working" id="section7.2">
                <h3>7.2.  How do convolutional neural networks work?</h3>
                <p>
                Convolutional neural networks are distinguished from other neural networks by their superior performance with image, speech, or audio signal inputs. They have three main types of layers, which are :
                </p>

                <ul style="list-style-type:disc">
                <li>Convolutional layer</li>
                <li>Pooling layer</li>
                <li>Fully-connected (FC) layer</li>
                </ul>
                <p>
                The convolutional layer is the first layer of a convolutional network. While convolutional layers can be followed by additional convolutional layers or pooling layers, the fully-connected layer is the final layer. With each layer, the CNN increases in its complexity, identifying greater portions of the image. Earlier layers focus on simple features, such as colors and edges. As the image data progresses through the layers of the CNN, it starts to recognize larger elements or shapes of the object until it finally identifies the intended object.
                </p>

                <br>

                <h3>i. Convolutional layer</h3>
                <p>
                The convolutional layer is the core building block of a CNN, and it is where the majority of computation occurs. It requires a few components, which are input data, a filter, and a feature map. Let’s assume that the input will be a color image, which is made up of a matrix of pixels in 3D. This means that the input will have three dimensions—a height, width, and depth—which correspond to RGB in an image. We also have a feature detector, also known as a kernel or a filter, which will move across the receptive fields of the image, checking if the feature is present. This process is known as a convolution.
                </p>

                <p>
                The feature detector is a two-dimensional (2-D) array of weights, which represents part of the image. While they can vary in size, the filter size is typically a 3x3 matrix; this also determines the size of the receptive field. The filter is then applied to an area of the image, and a dot product is calculated between the input pixels and the filter. This dot product is then fed into an output array. Afterwards, the filter shifts by a stride, repeating the process until the kernel has swept across the entire image. The final output from the series of dot products from the input and the filter is known as a feature map, activation map, or a convolved feature.
                </p>

                <p>
                Note that the weights in the feature detector remain fixed as it moves across the image, which is also known as parameter sharing. Some parameters, like the weight values, adjust during training through the process of backpropagation and gradient descent. However, there are three hyperparameters which affect the volume size of the output that need to be set before the training of the neural network begins. These include:
                </p>
                <ol type="a">
                <li>
                    The <b>number of filters</b> affects the depth of the output. For example, three distinct filters would yield three different feature maps, creating a depth of three. 
                </li>
                <li>
                    <b>Stride</b> is the distance, or number of pixels, that the kernel moves over the input matrix. While stride values of two or greater is rare, a larger stride yields a smaller output.
                </li>
                <li>
                    <b>Zero-padding</b> is usually used when the filters do not fit the input image. This sets all elements that fall outside of the input matrix to zero, producing a larger or equally sized output. There are three types of padding:
                    <ul style="list-style-type: disc">
                        <li>
                            <b>Valid padding : </b>This is also known as no padding. In this case, the last convolution is dropped if dimensions do not align.
                        </li>
                        <li>
                            <b>Same padding : </b>This padding ensures that the output layer has the same size as the input layer.
                        </li>
                        <li>
                            <b>Full padding : </b>This type of padding increases the size of the output by adding zeros to the border of the input.

                        </li>
                    </ul>
                </li>
                </ol>

                <p>After each convolution operation, a CNN applies a Rectified Linear Unit (ReLU) transformation to the feature map, introducing nonlinearity to the model.
                </p>

                <div class="fig1">
                <img src="https://www.ibm.com/content/dam/connectedassets-adobe-cms/worldwide-content/creative-assets/s-migr/ul/g/ed/92/iclh-diagram-convolutional-neural-networks.png" alt="cnn">
                <div class="caption">Fig 7.2</div>
                </div>

                <br>

                <h3>ii. Pooling layer</h3>
                <p>
                Pooling layers, also known as downsampling, conducts dimensionality reduction, reducing the number of parameters in the input. Similar to the convolutional layer, the pooling operation sweeps a filter across the entire input, but the difference is that this filter does not have any weights. Instead, the kernel applies an aggregation function to the values within the receptive field, populating the output array. There are two main types of pooling:
                </p>
                <ul style="list-style-type: disc;">
                <li>
                    <b>Max pooling</b> : As the filter moves across the input, it selects the pixel with the maximum value to send to the output array. As an aside, this approach tends to be used more often compared to average pooling.
                </li>
                <li>
                    <b>Average pooling</b> : As the filter moves across the input, it calculates the average value within the receptive field to send to the output array.
                </li>
                </ul>

                <p>
                While a lot of information is lost in the pooling layer, it also has a number of benefits to the CNN. They help to reduce complexity, improve efficiency, and limit risk of overfitting. 
                </p>

                <br>

                <h3>iii. Fully-connected layer</h3>
                <p>
                The name of the full-connected layer aptly describes itself. As mentioned earlier, the pixel values of the input image are not directly connected to the output layer in partially connected layers. However, in the fully-connected layer, each node in the output layer connects directly to a node in the previous layer.
                </p>
                <p>
                This layer performs the task of classification based on the features extracted through the previous layers and their different filters. While convolutional and pooling layers tend to use ReLu functions, FC layers usually leverage a softmax activation function to classify inputs appropriately, producing a probability from 0 to 1.
                </p>
            </div>

            <br>

            <div class="types" id="section7.3">
                <h3>7.3.  Different Types of CNN Models</h3>
                <ol type="i">
                <li>
                    <b>LeNet :</b> 
                    <ul style="list-style-type :circle">
                    <li>
                        LeNet is a pioneering convolutional neural network (CNN) architecture developed by Yann LeCun and his colleagues in the late 1990s. It was specifically designed for handwritten digit recognition, and was one of the first successful CNNs for image recognition.
                    </li>
                    <li>
                        LeNet consists of several layers of convolutional and pooling layers, followed by fully connected layers. The architecture includes two sets of convolutional and pooling layers, each followed by a subsampling layer, and then three fully connected layers.
                    </li>
                    <li>
                        The first convolutional layer uses a kernel of size 5×5 and applies 6 filters to the input image. The output of this layer is then passed through a pooling layer that reduces the spatial dimensions of the feature maps. The second convolutional layer uses a kernel of size 5×5 and applies 16 filters to the output of the first pooling layer. This is followed by another pooling layer and a subsampling layer.
                    </li>
                    <li>
                        The output of the subsampling layer is then passed through three fully connected layers, with 120, 84, and 10 neurons respectively. The last fully connected layer is used for classification, and produces a probability distribution over the 10 digits (0-9).
                    </li>
                    <li>
                        LeNet was trained on the MNIST dataset, which consists of 70,000 images of handwritten digits, and was able to achieve high recognition accuracy. The LeNet architecture, although relatively simple compared to current architectures, served as a foundation for many later CNNs, and it’s considered as a classic and simple architecture for image recognition tasks.
                    </li>
                    </ul>
                </li>
                <li>
                    <b>AlexNet :</b>
                    <ul style="list-style-type :circle">
                    <li>
                        AlexNet is a convolutional neural network (CNN) architecture that was developed by Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton in 2012. It was the first CNN to win the ImageNet Large Scale Visual Recognition Challenge (ILSVRC), a major image recognition competition, and it helped to establish CNNs as a powerful tool for image recognition.
                    </li>
                    <li>
                        AlexNet consists of several layers of convolutional and pooling layers, followed by fully connected layers. The architecture includes five convolutional layers, three pooling layers, and three fully connected layers.
                    </li>
                    <li>
                        The first two convolutional layers use a kernel of size 11×11 and apply 96 filters to the input image. The third and fourth convolutional layers use a kernel of size 5×5 and apply 256 filters. The fifth convolutional layer uses a kernel of size 3×3 and applies 384 filters. The output of these convolutional layers is then passed through max-pooling layers that reduce the spatial dimensions of the feature maps.
                    </li>
                    <li>
                        The output of the pooling layers is then passed through three fully connected layers, with 4096, 4096, and 1000 neurons respectively. The last fully connected layer is used for classification, and produces a probability distribution over the 1000 ImageNet classes.
                    </li>
                    <li>
                        AlexNet was trained on the ImageNet dataset, which consists of 1.2 million images with 1000 classes, and was able to achieve high recognition accuracy. The AlexNet architecture was the first to show that CNNs could significantly outperform traditional machine learning methods in image recognition tasks, and was an important step in the development of deeper architectures like VGGNet, GoogleNet, and ResNet.
                    </li>
                    </ul>
                </li>
                <li>
                    <b>Resnet :</b>
                    <ul style="list-style-type :circle">
                    <li>
                        ResNets (Residual Networks) are a type of deep learning algorithm that are particularly well-suited for image recognition and processing tasks. ResNets are known for their ability to train very deep networks without overfitting.
                    </li>
                    <li>
                        ResNets are often used for keypoint detection tasks. Keypoint detection is the task of locating specific points on an object in an image. For example, keypoint detection can be used to locate the eyes, nose, and mouth on a human face.
                    </li>
                    <li>
                        ResNets are well-suited for keypoint detection tasks because they can learn to extract features from images at different scales.
                    </li>
                    <li>
                        ResNets have achieved state-of-the-art results on many keypoint detection benchmarks, such as the COCO Keypoint Detection Challenge and the MPII Human Pose Estimation Dataset.
                    </li>
                    </ul>
                </li>
                <li>
                    <b>GoogleNet :</b>
                    <ul style="list-style-type :circle">
                        <li>
                            GoogleNet, also known as InceptionNet, is a type of deep learning algorithm that is particularly well-suited for image recognition and processing tasks. GoogleNet is known for its ability to achieve high accuracy on image classification tasks while using fewer parameters and computational resources than other state-of-the-art CNNs.
                        </li>
                        <li>
                            Inception modules are the key component of GoogleNet. They allow the network to learn features at different scales simultaneously, which improves the performance of the network on image classification tasks.

                        </li>
                        <li>
                            Inception modules are the key component of GoogleNet. They allow the network to learn features at different scales simultaneously, which improves the performance of the network on image classification tasks.
                        </li>
                        <li>
                            GoogleNet uses global average pooling to reduce the size of the feature maps before they are passed to the fully connected layers. This also helps to improve the performance of the network on image classification tasks.
                        </li>
                        <li>
                            GoogleNet uses factorized convolutions to reduce the number of parameters and computational resources required to train the network.
                        </li>
                        <li>
                            GoogleNet is a powerful tool for image classification, and it is being used in a wide variety of applications, such as GoogleNet can be used to classify images into different categories, such as cats and dogs, cars and trucks, and flowers and animals.
                        </li>
                    </ul>
                </li>
                <li>
                    <b>MobileNet :</b>
                    <ul style="list-style-type :circle">
                        <li>
                            MobileNets are a type of CNN that are particularly well-suited for image recognition and processing tasks on mobile and embedded devices.
                        </li>
                        <li>
                            MobileNets are known for their ability to achieve high accuracy on image classification tasks while using fewer parameters and computational resources than other state-of-the-art CNNs.
                        </li>
                        <li>
                            MobileNets are also being used for keypoint detection tasks.
                        </li>
                        <li>
                            MobileNets have achieved state-of-the-art results on many keypoint detection benchmarks.
                        </li>
                    </ul>
                </li>
                <li>
                    <b>VGG :</b>
                    <ul style="list-style-type :circle">
                        <li>
                            VGG is a type of convolutional neural network (CNN) that is known for its simplicity and effectiveness. VGGs are typically made up of a series of convolutional and pooling layers, followed by a few fully connected layers.
                        </li>
                        <li>
                            VGGs can be used by self-driving cars to detect and classify objects on the road, such as other vehicles, pedestrians, and traffic signs. This information can be used to help the car navigate safely.
                        </li>
                        <li>
                            VGGs are a powerful and versatile tool for image recognition tasks.
                        </li>
                    </ul>
                </li>
                </ol>

                <br>
            </div>

            <div class="pros" id="section7.4">
                <h3>
                7.4.  Advantages of CNN  
                </h3>
                <ol type="i">
                <li>CNNs can achieve state-of-the-art accuracy on a variety of image recognition tasks, such as image classification, object detection, and image segmentation.</li>
                <li>
                    CNNs can be very efficient, especially when implemented on specialized hardware such as GPUs.  
                </li>
                <li>
                    CNNs are relatively robust to noise and variations in the input data.
                </li>
                <li>
                    CNNs can be adapted to a variety of different tasks by simply changing the architecture of the network.
                </li>
                </ol>
            </div>

            <br>

            <div class="cons" id="section7.5">
                <h3>7.5.  Disadvantages of CNN</h3>
                <ol type="i">
                <li>
                    CNNs can be complex and difficult to train, especially for large datasets.
                </li>
                <li>
                    CNNs can require a lot of computational resources to train and deploy.
                </li>
                <li>
                    CNNs require a large amount of labeled data to train.
                </li>
                <li>
                    CNNs can be difficult to interpret, making it difficult to understand why they make the predictions they do.
                </li>
                </ol>
            </div>

            <br>

            <div class="applications" id="section7.6">
                <h3>7.6.  Applications of CNN</h3>
                <ol type="i">
                <li>
                    <b>Image classification :</b> CNNs are the state-of-the-art models for image classification. They can be used to classify images into different categories, such as cats and dogs, cars and trucks, and flowers and animals.
                </li>
                <li>
                    <b>Object detection :</b>CNNs can be used to detect objects in images, such as people, cars, and buildings. They can also be used to localize objects in images, which means that they can identify the location of an object in an image.
                </li>
                <li>
                    <b>Image segmentation :</b>CNNs can be used to segment images, which means that they can identify and label different objects in an image. This is useful for applications such as medical imaging and robotics.
                </li>
                <li>
                    <b>Video analysis :</b>CNNs can be used to analyze videos, such as tracking objects in a video or detecting events in a video. This is useful for applications such as video surveillance and traffic monitoring.
                </li>
                </ol>
            </div>

            <br>

            <div class="tools" id="section7.7">
                <h3>7.7.  What are some of the tools and frameworks for developing CNNs?</h3>
                <p>There are many popular tools and frameworks for developing CNNs, including:</p>
                <ol type="i">
                    <li>
                        <b>TensorFlow: </b>An open-source software library for deep learning developed by Google.
                    </li>
                    <li>
                        <b>PyTorch: </b>An open-source deep learning framework developed by Facebook.
                    </li>
                    <li>
                        <b>MXNet: </b>An open-source deep learning framework developed by Apache MXNet.
                    </li>
                    <li>
                        <b>Keras: </b>A high-level deep learning API for Python that can be used with TensorFlow, PyTorch, or MXNet.
                    </li>
                </ol>
            </div>
                </div> 

                <div class="section eight" id="section8">

                <div class="headline">
                8. Recurrent Neural Network(RNN)<hr size=".1px" color="gray">
                </div>

                <div class="introduction" id="section8.1">
                <h3>8.1. Introduction to RNN</h3>
                <p>
                    A recurrent neural network (RNN) is a deep learning model that is trained to process and convert a sequential data input into a specific sequential data output. Sequential data is data—such as words, sentences, or time-series data—where sequential components interrelate based on complex semantics and syntax rules. An RNN is a software system that consists of many interconnected components mimicking how humans perform sequential data conversions, such as translating text from one language to another. RNNs are largely being replaced by transformer-based artificial intelligence (AI) and large language models (LLM), which are much more efficient in sequential data processing.
                </p>
                <br>
                <p>
                    RNN is a type of Neural Network where the output from the previous step is fed as input to the current step. In traditional neural networks, all the inputs and outputs are independent of each other. Still, in cases when it is required to predict the next word of a sentence, the previous words are required and hence there is a need to remember the previous words. Thus RNN came into existence, which solved this issue with the help of a Hidden Layer. The main and most important feature of RNN is its Hidden state, which remembers some information about a sequence. The state is also referred to as Memory State since it remembers the previous input to the network. It uses the same parameters for each input as it performs the same task on all the inputs or hidden layers to produce the output. This reduces the complexity of parameters, unlike other neural networks.
                </p>
                <div class="fig1">
                    <img src="https://media.geeksforgeeks.org/wp-content/uploads/20231204125839/What-is-Recurrent-Neural-Network-660.webp" alt="ANN">
                    <div class="caption"><i>Fig 8.1 - Recurrent Neural Network</i></div>
                </div>
    
                </div>

                <br>

                <div class="Architecture" id="section8.2">
                <h3>
                    8.2. Recurrent Neural Network Architecture
                </h3>
                <p>
                    RNNs have the same input and output architecture as any other deep neural architecture. However, differences arise in the way information flows from input to output. Unlike Deep neural networks where we have different weight matrices for each Dense network in RNN, the weight across the network remains the same. It calculates state hidden state  Hi for every input Xi . By using the following formulas:
                    <br>
                    h= σ(UX + Wh-1 + B)
                    <br>
                    Y = O(Vh + C)
                    <br>
                    Hence 
                    <br>
                    Y = f (X, h , W, U, V, B, C)
                    <br>
                    Here S is the State matrix which has element si as the state of the network at timestep i
                    The parameters in the network are W, U, V, c, b which are shared across timestep
                </p>
                <div class="fig1">
                    <img src="https://media.geeksforgeeks.org/wp-content/uploads/20231204131544/recurrent_neural_networks-768.png" alt="ANN">
                    <div class="caption"><i>Fig 8.2 - Recurrent Neural Architecture </i>
                    </div>
                </div>
                </div>
            
                <br>

                <div class="working" id="section8.3" >
                <h3>8.3. How does a recurrent neural network work?</h3>
                <div class="fig1">
                    <img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2017/10/06/intro-gluon-1.gif" alt="RNN">
                    <div class="caption"><i>Fig- 8.3. layers of RNN</i></div>
                </div>
                <p>
                    RNNs are made of neurons: data-processing nodes that work together to perform complex tasks. The neurons are organized as input, output, and hidden layers. The input layer receives the information to process, and the output layer provides the result. Data processing, analysis, and prediction take place in the hidden layer.
                </p>
                <ol type="i">
                    <li>
                        <b>Hidden layer : </b>
                        RNNs work by passing the sequential data that they receive to the hidden layers one step at a time. However, they also have a self-looping or recurrent workflow: the hidden layer can remember and use previous inputs for future predictions in a short-term memory component. It uses the current input and the stored memory to predict the next sequence. 
                        <br>
                        For example, consider the sequence: Apple is red. You want the RNN to predict red when it receives the input sequence Apple is. When the hidden layer processes the word Apple, it stores a copy in its memory. Next, when it sees the word is, it recalls Apple from its memory and understands the full sequence: Apple is for context. It can then predict red for improved accuracy. This makes RNNs useful in speech recognition, machine translation, and other language modeling tasks.
                    </li>

                    <li>
                        <b>Training : </b>Machine learning (ML) engineers train deep neural networks like RNNs by feeding the model with training data and refining its performance. In ML, the neuron's weights are signals to determine how influential the information learned during training is when predicting the output. Each layer in an RNN shares the same weight. 
                        <br>
                        ML engineers adjust weights to improve prediction accuracy. They use a technique called backpropagation through time (BPTT) to calculate model error and adjust its weight accordingly. BPTT rolls back the output to the previous time step and recalculates the error rate. This way, it can identify which hidden state in the sequence is causing a significant error and readjust the weight to reduce the error margin.
                    </li>
                </ol>
                <br>
                <p>
                    The Recurrent Neural Network consists of multiple fixed activation function units, one for each time step. Each unit has an internal state which is called the hidden state of the unit. This hidden state signifies the past knowledge that the network currently holds at a given time step. This hidden state is updated at every time step to signify the change in the knowledge of the network about the past. The hidden state is updated using the following recurrence relation:-
                </p>
                <br>
                <p>
                    <b>The formula for calculating the current state:
                    </b>
                    <br>
                    <p>h<sub>t</sub> = f(h<sub>t-1</sub>) , x<sub>t</sub></p>
                    <br>
                    <p>
                        where,
                        <br>
                        <br>
                        h<sub>t</sub> -> current state <br>
                        h<sub>t-1</sub> -> previous state <br>
                        x<sub>t</sub> -> input state <br>
                    </p>
                    <br>
                    <p>
                        These parameters are updated using Backpropagation. However, since RNN works on sequential data here we use an updated backpropagation which is known as Backpropagation through time. 
                    </p>
                </p>
                </div>

                <br>

                <div class="bptt" id="section8.4">
                <h3>
                    8.4. Backpropagation Through Time (BPTT)
                </h3>
                <p>
                    In RNN the neural network is in an ordered fashion and since in the ordered network each variable is computed one at a time in a specified order like first h1 then h2 then h3 so on. Hence we will apply backpropagation throughout all these hidden time states sequentially.
                </p>
                <div class="fig1">
                    <img src="https://media.geeksforgeeks.org/wp-content/uploads/20231204132128/Backpropagation-Through-Time-(BPTT).webp" alt="bptt">
                    <div class="caption"><i>Fig- 8.4. Backpropagation Through Time (BPTT) In RNN</i></div>
                </div>
                <ul style="list-style-type: disc;">
                    <li>L(θ)(loss function) depends on h3</li>
                    <li>h3 in turn depends on h2 and W</li>
                    <li>h2 in turn depends on h1 and W</li>
                    <li>h1 in turn depends on h0 and W</li>
                    <li>where h0 is a constant starting state.</li>
                </ul>
                </div>

                <br>

                <div class="types" id="section8.5">
                <h3>
                   8.5. Types Of RNN 
                </h3>
                <p>
                    RNNs are often characterized by one-to-one architecture: one input sequence is associated with one output. However, you can flexibly adjust them into various configurations for specific purposes. The following are several common RNN types.
                </p>
                <br>
                <ol type="i">
                    <li>
                        <b>One to One : </b> This type of RNN behaves the same as any simple Neural network it is also known as Vanilla Neural Network. In this Neural network, there is only one input and one output. 
                        <br>
                        <div class="fig2">
                            <img src="https://media.geeksforgeeks.org/wp-content/uploads/20231204131135/One-to-One-300.webp" alt="1-1">
                            <div class="caption"><i>Fig 8.5.1. One to One RNN</i></div>
                        </div>
        
                    </li>
                    <li>
                        <b>
                            One To Many : 
                        </b> In this type of RNN, there is one input and many outputs associated with it. One of the most used examples of this network is Image captioning where given an image we predict a sentence having Multiple words. 
                        <br>
                        <div class="fig2">
                            <img src="https://media.geeksforgeeks.org/wp-content/uploads/20231204131304/One-to-Many-300.webp" alt="1-M">
                            <div class="caption"><i>Fig- 8.5.2. One to Many RNN</i>
                            </div>
                        </div>
                    </li>
                    <li>
                        <b>
                            Many to One : 
                        </b> In this type of network, Many inputs are fed to the network at several states of the network generating only one output. This type of network is used in the problems like sentimental analysis. Where we give multiple words as input and predict only the sentiment of the sentence as output. 
                        <div class="fig2">
                            <img src="https://media.geeksforgeeks.org/wp-content/uploads/20231204131355/Many-to-One-300.webp" alt="ANN">
                            <div class="caption"><i>Fig 8.5.3. Many to One RNN</i>
                            </div>
                        </div>
                    </li>
                    <li>
                        <b>
                            Many to Many : 
                        </b> In this type of neural network, there are multiple inputs and multiple outputs corresponding to a problem. One Example of this Problem will be language translation. In language translation, we provide multiple words from one language as input and predict multiple words from the second language as output.
                        <br>
                        <div class="fig2">
                            <img src="https://media.geeksforgeeks.org/wp-content/uploads/20231204131436/Many-to-Many-300.webp" alt="m-m">
                            <div class="caption"><i>Fig 8.5.4. Many to Many RNN</i>
                            </div>
                        </div>
                    </li>
                </ol>
                </div>

                <br>

                <div class="comparison" id="section8.6">
                <h3>
                    8.6. How do RNN compare to other deep learning networks?
                </h3>
                <br>
                <p>
                    <b>
                        Recurrent neural network vs. feed-forward neural network
                    </b><br><br>
                    Like RNNs, feed-forward neural networks are artificial neural networks that pass information from one end to the other end of the architecture. A feed-forward neural network can perform simple classification, regression, or recognition tasks, but it can’t remember the previous input that it has processed. For example, it forgets Apple by the time its neuron processes the word is. The RNN overcomes this memory limitation by including a hidden memory state in the neuron.
                </p>
                <br><p>
                    <b>
                        Recurrent neural network vs. convolutional neural networks
                    </b> <br><br>
                    Convolutional neural networks are artificial neural networks that are designed to process spatial data. You can use convolutional neural networks to extract spatial information from videos and images by passing them through a series of convolutional and pooling layers in the neural network. RNNs are designed to capture long-term dependencies in sequential data.
                </p>
                </div>

                <br>

                <div class="proscons" id="section8.7">
                    <h3>8.7. Pros and cons of RNN</h3>
                    <p><b>Pros :</b></p>
                    <ol type="i">
                        <li>
                            An RNN remembers each and every piece of information through time. It is useful in time series prediction only because of the feature to remember previous inputs as well. This is called Long Short Term Memory.
                        </li>
                        <li>
                            Recurrent neural networks are even used with convolutional layers to extend the effective pixel neighborhood.
                        </li>
                    </ol>
                    <p><b>Cons :</b></p>
                    <ol type="i">
                        <li>
                            Gradient vanishing and exploding problems.
                        </li>
                        <li>
                            Training an RNN is a very difficult task.
                        </li>
                        <li>
                            It cannot process very long sequences if using tanh or relu as an activation function.
                        </li>
                    </ol>
                </div>

                <br>

                <div class="applications" id="section8.8">
                    <h3>8.8. Applications of Recurrent Neural Network
                    </h3>
                    <ol type="i">
                        <li>
                            Language Modelling and Generating Text
                        </li>
                        <li>
                            Speech Recognition
                        </li>
                        <li>
                            Machine Translation
                        </li>
                        <li>
                            Image Recognition, Face detection
                        </li>
                        <li>
                            Time series Forecasting
                        </li>
                    </ol>
                </div>

                </div>

               <!--
    
                <div class="fig2">
                    <img src="BNN.png" alt="ANN">
                    <div class="caption"><i>Fig 6.2</i>
                    </div>
                </div>

                <div class="fig1">
                    <img src="Neural-Networks-Architecture.png" alt="ANN">
                    <div class="caption"><i>Fig 6.1</i></div>
                </div>
    
                -->


            </div>

            </div>

        </div>
            
        <div class="next">
            <a href="next.html">>>next>></a>
        </div>

    <footer>
        This is footer
    </footer>
    
    
<script>
    $(document).ready(function(){
        $("#scrollToTop").click(function() {
            $("html, body").animate({ scrollTop: 0 }, "slow");
        });
    });
</script>

    
</body>
</html>
